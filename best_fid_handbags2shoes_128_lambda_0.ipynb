{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0055fbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['imgs']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cache/selikhanovych/miniconda3/envs/stargan-v2/lib/python3.6/site-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['imgs']>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-99a21a7b0a8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                              img_size=IMG_SIZE, batch_size=32)\n\u001b[1;32m     37\u001b[0m train_loader_b, test_loader_b = load_dataset(DATASET2, DATASET2_PATH,\n\u001b[0;32m---> 38\u001b[0;31m                                              img_size=IMG_SIZE, batch_size=32)\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cache/selikhanovych/extremal_ot/stargan-v2/test_utils.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(name, path, img_size, batch_size, test_ratio)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'shoes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'handbag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outdoor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'church'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'celeba_female'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'celeba_male'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aligned_anime_faces'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cache/selikhanovych/extremal_ot/stargan-v2/test_utils.py\u001b[0m in \u001b[0;36mh5py_to_dataset\u001b[0;34m(path, img_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Get the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma_group_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cache/selikhanovych/miniconda3/envs/stargan-v2/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't iterate over a scalar dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/cache/selikhanovych/miniconda3/envs/stargan-v2/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;31m# Perform the dataspace selection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mselection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnselect\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cache/selikhanovych/miniconda3/envs/stargan-v2/lib/python3.6/site-packages/h5py/_hl/selections.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(shape, args, dataset)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_selector.pyx\u001b[0m in \u001b[0;36mh5py._selector.Selector.make_selection\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/cache/selikhanovych/miniconda3/envs/stargan-v2/lib/python3.6/site-packages/h5py/_hl/selections.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, spaceid, hyperslab)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaceid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperslab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaceid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhyperslab\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperslab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cache/selikhanovych/miniconda3/envs/stargan-v2/lib/python3.6/site-packages/h5py/_hl/selections.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, spaceid)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspaceid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaceid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspaceid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from easydict import EasyDict as edict\n",
    "from test_utils import load_dataset, LoaderSampler, tensor2img\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from core.my_solver import Solver\n",
    "from core.fid_score import calculate_frechet_distance\n",
    "from core.my_metrics import get_Z_pushed_loader_stats, calculate_cost\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "\n",
    "DATASET1, DATASET1_PATH = 'handbag', '../data/handbag_128.hdf5'\n",
    "DATASET2, DATASET2_PATH = 'shoes', '../data/shoes_128.hdf5'\n",
    "\n",
    "IMG_SIZE = 128\n",
    "\n",
    "filename = 'stats/{}_{}_test.json'.format(DATASET2, IMG_SIZE)\n",
    "with open(filename, 'r') as fp:\n",
    "    data_stats = json.load(fp)\n",
    "    mu_data, sigma_data = data_stats['mu'], data_stats['sigma']\n",
    "del data_stats\n",
    "\n",
    "device = 'cuda'\n",
    "input_shape = (3, IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "train_loader_a, test_loader_a = load_dataset(DATASET1, DATASET1_PATH,\n",
    "                                             img_size=IMG_SIZE, batch_size=32)\n",
    "train_loader_b, test_loader_b = load_dataset(DATASET2, DATASET2_PATH,\n",
    "                                             img_size=IMG_SIZE, batch_size=32)\n",
    "\n",
    "n_batches = min(len(train_loader_a), len(train_loader_b))\n",
    "\n",
    "X_sampler = LoaderSampler(train_loader_a, device=device)\n",
    "X_test_sampler = LoaderSampler(test_loader_a, device=device)\n",
    "Y_sampler = LoaderSampler(train_loader_b, device=device)\n",
    "Y_test_sampler = LoaderSampler(test_loader_b, device=device)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "X_fixed = X_sampler.sample(12)\n",
    "Y_fixed = Y_sampler.sample(12)\n",
    "\n",
    "X_test_fixed = X_test_sampler.sample(12)\n",
    "Y_test_fixed = Y_test_sampler.sample(12)\n",
    "\n",
    "indices = [0, 243, 2, 35, 189, 246]\n",
    "X = torch.stack([test_loader_a.dataset[indices[i]][0].to(device) for i in range(len(indices))])\n",
    "                \n",
    "lambdas_arr = [0.0]\n",
    "                \n",
    "fig, axes = plt.subplots(1 + len(lambdas_arr), len(indices), figsize=(2*len(indices) + 1, 2*len(lambdas_arr) + 2), dpi=200)\n",
    "\n",
    "\n",
    "transform = Compose([Resize((IMG_SIZE, IMG_SIZE)),\n",
    "                     ToTensor(),\n",
    "                     Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "test_dataset_a = ImageFolder('/cache/selikhanovych/OT_competitors/stargan-v2/data/celeba2anime_test/celeba_female', \n",
    "                             transform)\n",
    "test_loader_a = DataLoader(dataset=test_dataset_a,\n",
    "                           batch_size=20,\n",
    "                           num_workers=4,\n",
    "                           pin_memory=True,\n",
    "                           shuffle=False)\n",
    "X_test_sampler = LoaderSampler(test_loader_a)\n",
    "\n",
    "\n",
    "for k, lambda_val in enumerate(lambdas_arr):\n",
    "    args = edict({\n",
    "    'img_size': 128,\n",
    "    'num_domains': 2,\n",
    "    'latent_dim': 16,\n",
    "    'hidden_dim': 512,\n",
    "    'style_dim': 64,\n",
    "    'lambda_reg': 1.0,\n",
    "    'lambda_cyc': 1.0,\n",
    "    'lambda_sty': 1.0,\n",
    "    'lambda_ds': 1.0,\n",
    "    'lambda_id': lambda_id,\n",
    "    'ds_iter': 100000,\n",
    "    'w_hpf': -1.0,\n",
    "    'randcrop_prob': 0.5,\n",
    "    'total_iters': 100000,\n",
    "    'resume_iter': 0,\n",
    "    'batch_size': 16,\n",
    "    'val_batch_size': 32,\n",
    "    'lr': 1e-4,\n",
    "    'f_lr': 1e-6,\n",
    "    'beta1': 0.0,\n",
    "    'beta2': 0.99,\n",
    "    'weight_decay': 1e-4,\n",
    "    'num_outs_per_domain': 10,\n",
    "    'mode': 'train',\n",
    "    'num_workers': 4,\n",
    "    'seed': 777,\n",
    "    'train_img_dir': '/cache/selikhanovych/extremal_ot/stargan-v2/data/handbag2shoes_train',\n",
    "    'val_img_dir': '/cache/selikhanovych/extremal_ot/stargan-v2/data/handbag2shoes_test',\n",
    "    'sample_dir': 'expr/samples',\n",
    "    'checkpoint_dir': f'/cache/selikhanovych/extremal_ot/stargan-v2/handbag2shoes_exps/checkpoints_lambda_{lambda_id}',\n",
    "    'eval_dir': 'expr/eval',\n",
    "    'result_dir': 'expr/results',\n",
    "    'src_dir': 'assets/representative/celeba_hq/src',\n",
    "    'ref_dir': 'assets/representative/celeba_hq/ref',\n",
    "    'inp_dir': 'assets/representative/custom/female',\n",
    "    'out_dir': 'assets/representative/celeba_hq/src/female',\n",
    "    'wing_path': 'expr/checkpoints/wing.ckpt',\n",
    "    'lm_path': 'expr/checkpoints/celeba_lm_mean.npz',\n",
    "    'print_every': 10,\n",
    "    'sample_every': 4000,\n",
    "    'save_every': 4000,\n",
    "    'eval_every': 4000,\n",
    "    'device': 0,\n",
    "\n",
    "    'target_dataset': 'shoes',\n",
    "    'OUTPUT_PATH': f'/cache/selikhanovych/extremal_ot/stargan-v2/handbag2shoes_exps/checkpoints_lambda_{lambda_id}',\n",
    "    'domains': {\n",
    "        'source': 'handbag',\n",
    "        'target': 'shoes',\n",
    "    },\n",
    "    'train_a': '/cache/selikhanovych/extremal_ot/stargan-v2/data/handbag2shoes_train/handbag',\n",
    "    'train_b': '/cache/selikhanovych/extremal_ot/stargan-v2/data/handbag2shoes_train/shoes',\n",
    "    'test_a': '/cache/selikhanovych/extremal_ot/stargan-v2/data/handbag2shoes_test/handbag',\n",
    "    'test_b': '/cache/selikhanovych/extremal_ot/stargan-v2/data/handbag2shoes_test/shoes',\n",
    "\n",
    "    'n_epochs': 1\n",
    "    })\n",
    "                \n",
    "    eval_trg_domain = args.domains['target']\n",
    "    eval_src_domain = args.domains['source']\n",
    "\n",
    "    domains = os.listdir(args.val_img_dir)\n",
    "    domains.sort()\n",
    "\n",
    "    final_trg_index = -1\n",
    "    final_src_index = -1\n",
    "\n",
    "    for trg_idx, trg_domain in enumerate(domains):\n",
    "        src_domains = [x for x in domains if x != trg_domain]\n",
    "        for src_idx, src_domain in enumerate(src_domains):\n",
    "            if src_domain == eval_src_domain and trg_domain == eval_trg_domain:\n",
    "                final_trg_index = trg_idx\n",
    "                final_src_index = src_idx\n",
    "\n",
    "    eval_trg_domain = args.domains['target']\n",
    "    eval_src_domain = args.domains['source']\n",
    "\n",
    "    domains = os.listdir(args.val_img_dir)\n",
    "    domains.sort()\n",
    "    num_domains = len(domains)\n",
    "    for trg_idx, trg_domain in enumerate(domains):\n",
    "        src_domains = [x for x in domains if x != trg_domain]\n",
    "        for src_idx, src_domain in enumerate(src_domains):\n",
    "            if src_domain == eval_src_domain and trg_domain == eval_trg_domain:\n",
    "                print(f\"trg_idx = {trg_idx}, trg_domain = {trg_domain}, src_domain = {src_domain}\")\n",
    "                break\n",
    "        break\n",
    "\n",
    "    print(f\"trg_idx = {trg_idx}, lambda_id = {args.lambda_id}\")\n",
    "                \n",
    "    solver = Solver(args)\n",
    "    iterations = [1 + 4000*(i + 1) for i in range(24)]\n",
    "    best_fid = np.inf\n",
    "    best_iter = 0\n",
    "    for iteration in iterations:\n",
    "        print(f\"iteration = {iteration}\")\n",
    "        solver._load_checkpoint(iteration)\n",
    "\n",
    "        nets_ema = solver.nets_ema\n",
    "        nets_ema.mapping_network.eval()\n",
    "        nets_ema.generator.eval()\n",
    "\n",
    "        torch.manual_seed(0xBADBEEF)\n",
    "        np.random.seed(0xBADBEEF)\n",
    "\n",
    "        num_calculation_fid = 1\n",
    "        fid_values = []\n",
    "        l2_cost_values = []\n",
    "        l1_cost_values = []\n",
    "\n",
    "        for i in range(num_calculation_fid):\n",
    "            mu, sigma = get_Z_pushed_loader_stats(nets_ema, args.domains, args, device,\n",
    "                                                  batch_size=37, n_epochs=args.n_epochs)\n",
    "            fid = calculate_frechet_distance(solver.mu_data, solver.sigma_data, mu, sigma)\n",
    "            print(f\"FID = {fid}\")\n",
    "            fid_values.append(fid)\n",
    "\n",
    "            l1_cost = calculate_cost(nets_ema, args, trg_idx, X_test_sampler.loader, device,\n",
    "                       cost_type='l1', verbose=True)\n",
    "            print(f\"l1 = {l1_cost}\")\n",
    "            l1_cost_values.append(l1_cost)\n",
    "\n",
    "            l2_cost = calculate_cost(nets_ema, args, trg_idx, X_test_sampler.loader, device,\n",
    "                       cost_type='mse', verbose=True)\n",
    "            print(f\"l2 = {l2_cost}\")\n",
    "            l2_cost_values.append(l2_cost)\n",
    "            \n",
    "        if fid < best_fid:\n",
    "            best_fid = fid\n",
    "            best_iter = iteration\n",
    "            print(f\"best fid = {best_fid}, best_iter = {best_iter}, lambda = {lambda_val}, l1 = {l1_cost}, l2 = {l2_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b4ce1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stargan_v2",
   "language": "python",
   "name": "stargan_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
