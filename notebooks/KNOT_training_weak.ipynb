{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import gc\n",
    "\n",
    "from src import distributions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.resnet2 import ResNet_D\n",
    "from src.cunet import CUNet\n",
    "\n",
    "from src.tools import unfreeze, freeze\n",
    "from src.tools import load_dataset, get_Z_pushed_loader_stats\n",
    "from src.fid_score import calculate_frechet_distance\n",
    "from src.tools import weights_init_D\n",
    "from src.plotters import plot_random_Z_images, plot_Z_images\n",
    "\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import wandb\n",
    "from src.tools import fig2data, fig2img # for wandb\n",
    "\n",
    "# This needed to use dataloaders for some datasets\n",
    "from PIL import PngImagePlugin\n",
    "LARGE_ENOUGH_NUMBER = 100\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DEVICE_IDS = [0]\n",
    "\n",
    "# DATASET2, DATASET2_PATH = 'handbag', '../../data/handbag_128.hdf5'\n",
    "DATASET2, DATASET2_PATH = 'shoes', '../../data/shoes_128.hdf5'\n",
    "DATASET1, DATASET1_PATH = 'dtd', '../../data/dtd/images'\n",
    "\n",
    "# DATASET1, DATASET1_PATH = 'handbag', '../../data/handbag_128.hdf5'\n",
    "# DATASET2, DATASET2_PATH = 'shoes', '../../data/shoes_128.hdf5'\n",
    "\n",
    "# DATASET1, DATASET1_PATH = 'outdoor', '../../data/outdoor_128.hdf5'\n",
    "# DATASET2, DATASET2_PATH = 'church', '../../data/church_128.hdf5'\n",
    "\n",
    "# DATASET2, DATASET2_PATH = 'celeba_female', '../../data/img_align_celeba'\n",
    "# DATASET1, DATASET1_PATH = 'aligned_anime_faces', '../../data/aligned_anime_faces'\n",
    "\n",
    "T_ITERS = 10\n",
    "f_LR, T_LR = 1e-4, 1e-4\n",
    "IMG_SIZE = 64\n",
    "\n",
    "ZC = 128\n",
    "Z_STD = 1.\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "Z_SIZE = 4\n",
    "\n",
    "PLOT_INTERVAL = 500\n",
    "COST = 'energy' # 'laplacian' #'gaussian' #'weak_mse' # \n",
    "CPKT_INTERVAL = 2000\n",
    "MAX_STEPS = 100001\n",
    "SEED = 0xBADBEEF\n",
    "\n",
    "GAMMA0, GAMMA1 = 0.0, 0.333\n",
    "GAMMA_ITERS = 20000\n",
    "\n",
    "# CONTINUE = -1 <-- to continue training from a XX9999 checkpoint\n",
    "\n",
    "EXP_NAME = f'{DATASET1}_{DATASET2}_T{T_ITERS}_{COST}_{IMG_SIZE}'\n",
    "OUTPUT_PATH = '../checkpoints/{}/{}_{}_{}/'.format(COST, DATASET1, DATASET2, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    DATASET1=DATASET1,\n",
    "    DATASET2=DATASET2, \n",
    "    T_ITERS=T_ITERS,\n",
    "    f_LR=f_LR, T_LR=T_LR,\n",
    "    BATCH_SIZE=BATCH_SIZE\n",
    ")\n",
    "\n",
    "AUGMENTED_DATASETS = ['dtd']\n",
    "FID_EPOCHS = 50 if DATASET1 in AUGMENTED_DATASETS else 1\n",
    "    \n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f'cuda:{DEVICE_IDS[0]}')\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../stats/{}_{}_test.json'.format(DATASET2, IMG_SIZE)\n",
    "with open(filename, 'r') as fp:\n",
    "    data_stats = json.load(fp)\n",
    "    mu_data, sigma_data = data_stats['mu'], data_stats['sigma']\n",
    "del data_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Samplers (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampler, X_test_sampler = load_dataset(DATASET1, DATASET1_PATH, img_size=IMG_SIZE)\n",
    "Y_sampler, Y_test_sampler = load_dataset(DATASET2, DATASET2_PATH, img_size=IMG_SIZE)\n",
    "    \n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ResNet_D(IMG_SIZE, nc=3).cuda()\n",
    "f.apply(weights_init_D)\n",
    "T = CUNet(3, 3, ZC, base_factor=48).cuda()\n",
    "\n",
    "if len(DEVICE_IDS) > 1:\n",
    "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
    "    f = nn.DataParallel(f, device_ids=DEVICE_IDS)\n",
    "    \n",
    "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
    "print('f params:', np.sum([np.prod(p.shape) for p in f.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
    "f_opt = torch.optim.Adam(f.parameters(), lr=f_LR, weight_decay=1e-10)\n",
    "T_scheduler = torch.optim.lr_scheduler.MultiStepLR(T_opt, milestones=[15000, 25000, 40000, 55000, 70000], gamma=0.5)\n",
    "f_scheduler = torch.optim.lr_scheduler.MultiStepLR(f_opt, milestones=[15000, 25000, 40000, 55000, 70000], gamma=0.5)\n",
    "\n",
    "# if CONTINUE > -1:\n",
    "#     T_opt.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'T_opt_{SEED}_{CONTINUE}.pt')))\n",
    "#     T_scheduler.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'T_scheduler_{SEED}_{CONTINUE}.pt')))\n",
    "#     T.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'T_{SEED}_{CONTINUE}.pt')))\n",
    "#     f_opt.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'f_opt_{SEED}_{CONTINUE}.pt')))\n",
    "#     f.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'f_{SEED}_{CONTINUE}.pt')))\n",
    "#     f_scheduler.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'f_scheduler_{SEED}_{CONTINUE}.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0xBADBEEF); np.random.seed(0xBADBEEF)\n",
    "X_fixed, Y_fixed = X_sampler.sample(10), Y_sampler.sample(10)\n",
    "X_fixed = X_fixed[:,None].repeat(1,4,1,1,1)\n",
    "with torch.no_grad():\n",
    "    Z_fixed = torch.randn(10, 4, ZC, 1, 1, device='cuda') * Z_STD\n",
    "    XZ_fixed = (X_fixed, Z_fixed)\n",
    "del X_fixed\n",
    "\n",
    "X_test_fixed, Y_test_fixed = X_test_sampler.sample(10), Y_test_sampler.sample(10)\n",
    "X_test_fixed = X_test_fixed[:,None].repeat(1,4,1,1,1)\n",
    "with torch.no_grad():\n",
    "    Z_test_fixed = torch.randn(10, 4, ZC, 1, 1, device='cuda') * Z_STD\n",
    "    XZ_test_fixed = (X_test_fixed, Z_test_fixed,)\n",
    "del X_test_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plot_Z_images(XZ_fixed, Y_fixed, T)\n",
    "fig, axes = plot_random_Z_images(X_sampler, ZC, Z_STD, Y_sampler, T)\n",
    "fig, axes = plot_Z_images(XZ_test_fixed, Y_test_fixed, T)\n",
    "fig, axes = plot_random_Z_images(X_test_sampler, ZC, Z_STD, Y_test_sampler, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(name=EXP_NAME, project='unpairedot', entity='gunsandroses', config=config)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for step in tqdm(range(CONTINUE+1, MAX_STEPS)):\n",
    "    gamma = min(GAMMA1, GAMMA0 + (GAMMA1-GAMMA0) * step / GAMMA_ITERS)\n",
    "    # T optimization\n",
    "    unfreeze(T); freeze(f)\n",
    "    for t_iter in range(T_ITERS): \n",
    "        T_opt.zero_grad()\n",
    "        X = X_sampler.sample(BATCH_SIZE)[:,None].repeat(1,Z_SIZE,1,1,1)\n",
    "        with torch.no_grad():\n",
    "            Z = torch.randn(BATCH_SIZE, Z_SIZE, ZC, 1, 1, device='cuda') * Z_STD\n",
    "        T_XZ = T(\n",
    "            X.flatten(start_dim=0, end_dim=1), Z.flatten(start_dim=0, end_dim=1)\n",
    "        ).permute(1,2,3,0).reshape(3, IMG_SIZE, IMG_SIZE, -1, Z_SIZE).permute(3,4,0,1,2)\n",
    "        \n",
    "        if COST == 'weak_mse':\n",
    "            # Weak quadratic cost (normalized by DIM)\n",
    "            T_var = T_XZ.var(dim=1).mean()\n",
    "            T_loss = F.mse_loss(X[:,0], T_XZ.mean(dim=1)).mean() - \\\n",
    "            f(T_XZ.flatten(start_dim=0, end_dim=1)).mean() +  T_var * (1 - gamma - 1. / Z_SIZE)\n",
    "        elif COST == 'energy':\n",
    "            # Energy-based quadratic cost (for distance-induced kernel)\n",
    "            T_var = .5 * torch.cdist(T_XZ.flatten(start_dim=2), T_XZ.flatten(start_dim=2)).mean() * Z_SIZE / (Z_SIZE -1)\n",
    "            T_loss = (X-T_XZ).flatten(start_dim=2).norm(dim=2).mean() - \\\n",
    "            f(T_XZ.flatten(start_dim=0, end_dim=1)).mean() - gamma * T_var\n",
    "        elif COST == 'gaussian':\n",
    "            # Gaussian kernel (normalized by DIM)\n",
    "            idx = torch.triu_indices(Z_SIZE, Z_SIZE, offset=1)\n",
    "            T_var = 1 - torch.exp(\n",
    "                -.5*(T_XZ[:,idx[0]]-T_XZ[:,idx[1]]).square().flatten(start_dim=2).mean(dim=2)\n",
    "            ).mean()\n",
    "            T_loss = 1 - torch.exp(-0.5 * (X-T_XZ).square().flatten(start_dim=2).mean(dim=2)).mean() -\\\n",
    "            f(T_XZ.flatten(start_dim=0, end_dim=1)).mean() - gamma * T_var\n",
    "        elif COST == 'laplacian':\n",
    "            # Laplacian kernel (normalized by DIM)\n",
    "            idx = torch.triu_indices(Z_SIZE, Z_SIZE, offset=1)\n",
    "            T_var = 1 - torch.exp(\n",
    "                -(T_XZ[:,idx[0]]-T_XZ[:,idx[1]]).square().flatten(start_dim=2).mean(dim=2).sqrt()\n",
    "            ).mean()\n",
    "            T_loss = 1 - torch.exp(-(X-T_XZ).square().flatten(start_dim=2).mean(dim=2).sqrt()).mean() -\\\n",
    "            f(T_XZ.flatten(start_dim=0, end_dim=1)).mean() - gamma * T_var\n",
    "        else:\n",
    "            raise Exception(\"I do know know this cost!\")\n",
    "        \n",
    "        T_loss.backward(); T_opt.step()\n",
    "    T_scheduler.step()\n",
    "    wandb.log({'var' : T_var.item()}, step=step)\n",
    "    del T_loss, T_XZ, X, Z, T_var; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    # f optimization\n",
    "    freeze(T); unfreeze(f)\n",
    "    X = X_sampler.sample(BATCH_SIZE)\n",
    "    with torch.no_grad():\n",
    "        Z = torch.randn(BATCH_SIZE, ZC, 1, 1, device='cuda') * Z_STD\n",
    "        T_XZ = T(X,Z)\n",
    "    Y = Y_sampler.sample(BATCH_SIZE)\n",
    "    f_opt.zero_grad()\n",
    "    f_loss = f(T_XZ).mean() - f(Y).mean()\n",
    "    f_loss.backward(); f_opt.step(); f_scheduler.step()\n",
    "    wandb.log({f'f_loss' : f_loss.item()}, step=step)\n",
    "    del f_loss, Y, X, T_XZ, Z; gc.collect(); torch.cuda.empty_cache()\n",
    "            \n",
    "    if step % PLOT_INTERVAL == 0:\n",
    "        print('Plotting')\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        fig, axes = plot_Z_images(XZ_fixed, Y_fixed, T)\n",
    "        wandb.log({'Fixed Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_random_Z_images(X_sampler, ZC, Z_STD,  Y_sampler, T)\n",
    "        wandb.log({'Random Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_Z_images(XZ_test_fixed, Y_test_fixed, T)\n",
    "        wandb.log({'Fixed Test Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_random_Z_images(X_test_sampler, ZC, Z_STD,  Y_test_sampler, T)\n",
    "        wandb.log({'Random Test Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "    \n",
    "    if step % CPKT_INTERVAL == CPKT_INTERVAL - 1:\n",
    "        freeze(T); \n",
    "        torch.save(T.state_dict(), os.path.join(OUTPUT_PATH, f'T_{SEED}_{step}.pt'))\n",
    "#         torch.save(f.state_dict(), os.path.join(OUTPUT_PATH, f'f_{SEED}_{step}.pt'))\n",
    "#         torch.save(f_opt.state_dict(), os.path.join(OUTPUT_PATH, f'f_opt_{SEED}_{step}.pt'))\n",
    "#         torch.save(T_opt.state_dict(), os.path.join(OUTPUT_PATH, f'T_opt_{SEED}_{step}.pt'))\n",
    "#         torch.save(f_scheduler.state_dict(), os.path.join(OUTPUT_PATH, f'f_scheduler_{SEED}_{step}.pt'))\n",
    "#         torch.save(T_scheduler.state_dict(), os.path.join(OUTPUT_PATH, f'T_scheduler_{SEED}_{step}.pt'))\n",
    "        \n",
    "        print('Computing FID')\n",
    "        mu, sigma = get_Z_pushed_loader_stats(T, X_test_sampler.loader, ZC=ZC, Z_STD=Z_STD, n_epochs=FID_EPOCHS)\n",
    "        fid = calculate_frechet_distance(mu_data, sigma_data, mu, sigma)\n",
    "        wandb.log({f'FID (Test)' : fid}, step=step)\n",
    "        del mu, sigma\n",
    "    \n",
    "    gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
