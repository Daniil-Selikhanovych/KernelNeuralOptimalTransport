{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f85c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import gc\n",
    "\n",
    "from src import distributions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.resnet2 import ResNet_D\n",
    "from src.cunet import CUNet\n",
    "\n",
    "from src.tools import unfreeze, freeze\n",
    "from src.tools import load_dataset, get_Z_pushed_loader_stats\n",
    "from src.fid_score import calculate_frechet_distance\n",
    "from src.tools import weights_init_D\n",
    "from src.plotters import plot_random_Z_images, plot_Z_images\n",
    "\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from src.tools import fig2data, fig2img # for wandb\n",
    "\n",
    "# This needed to use dataloaders for some datasets\n",
    "from PIL import PngImagePlugin\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "SEED = 15\n",
    "DEVICE_IDS = [4, 5]\n",
    "\n",
    "# DATASET2, DATASET2_PATH = 'handbag', '../../data/handbag_128.hdf5'\n",
    "# DATASET1, DATASET1_PATH = 'shoes', '../../data/shoes_128.hdf5'\n",
    "# DATASET2, DATASET2_PATH = 'handbag', '../../data/handbag_128.hdf5'\n",
    "\n",
    "# DATASET1, DATASET1_PATH = 'handbag', '../../data/handbag_128.hdf5'\n",
    "# DATASET2, DATASET2_PATH = 'shoes', '../../data/shoes_128.hdf5'\n",
    "\n",
    "# DATASET1, DATASET1_PATH = 'outdoor', '../../data/outdoor_128.hdf5'\n",
    "# DATASET2, DATASET2_PATH = 'church', '../../data/church_128.hdf5'\n",
    "\n",
    "DATASET1, DATASET1_PATH = 'celeba_female', '../../data/img_align_celeba'\n",
    "DATASET2, DATASET2_PATH = 'aligned_anime_faces', '../../data/aligned_anime_faces'\n",
    "\n",
    "T_ITERS = 10\n",
    "D_LR, T_LR = 1e-4, 1e-4\n",
    "IMG_SIZE = 32\n",
    "\n",
    "ZC = 128\n",
    "Z_STD = 1.\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "Z_SIZE = 4\n",
    "\n",
    "PLOT_INTERVAL = 500\n",
    "COST = 'weak_mse' # 'laplacian' #'gaussian' #'weak_mse' # \n",
    "CPKT_INTERVAL = 2000\n",
    "MAX_STEPS = 100001\n",
    "\n",
    "GAMMA0, GAMMA1 = 0.0, 2.0\n",
    "GAMMA_ITERS = 20000\n",
    "\n",
    "CONTINUE = -1\n",
    "\n",
    "EXP_NAME = f'{DATASET1}_{DATASET2}_T{T_ITERS}_{COST}_{IMG_SIZE}'\n",
    "OUTPUT_PATH = '../my_checkpoints/{}/{}_{}_{}_seed_{}_gamma_{}/'.format(COST, DATASET1, DATASET2, IMG_SIZE, SEED, GAMMA1)\n",
    "\n",
    "config = dict(\n",
    "    DATASET1=DATASET1,\n",
    "    DATASET2=DATASET2, \n",
    "    T_ITERS=T_ITERS,\n",
    "    D_LR=D_LR, T_LR=T_LR,\n",
    "    BATCH_SIZE=BATCH_SIZE\n",
    ")\n",
    "\n",
    "FID_EPOCHS = 1\n",
    "    \n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f'cuda:{DEVICE_IDS[0]}')\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "    \n",
    "writer = SummaryWriter(os.path.join(OUTPUT_PATH, \"tensorboard\"))\n",
    "path_to_save_fig = os.path.join(OUTPUT_PATH, \"figs\")\n",
    "if not os.path.exists(path_to_save_fig):\n",
    "    os.makedirs(path_to_save_fig)\n",
    "\n",
    "path_to_save_models = os.path.join(OUTPUT_PATH, \"models\")\n",
    "if not os.path.exists(path_to_save_models):\n",
    "    os.makedirs(path_to_save_models)\n",
    "    \n",
    "filename = '../stats/{}_{}_test.json'.format(DATASET2, IMG_SIZE)\n",
    "with open(filename, 'r') as fp:\n",
    "    data_stats = json.load(fp)\n",
    "    mu_data, sigma_data = data_stats['mu'], data_stats['sigma']\n",
    "del data_stats\n",
    "\n",
    "X_sampler, X_test_sampler = load_dataset(DATASET1, DATASET1_PATH, img_size=IMG_SIZE)\n",
    "Y_sampler, Y_test_sampler = load_dataset(DATASET2, DATASET2_PATH, img_size=IMG_SIZE)\n",
    "    \n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "D = ResNet_D(IMG_SIZE, nc=3).cuda()\n",
    "D.apply(weights_init_D)\n",
    "T = CUNet(3, 3, ZC, base_factor=48).cuda()\n",
    "\n",
    "if len(DEVICE_IDS) > 1:\n",
    "    T = nn.DataParallel(T, device_ids=DEVICE_IDS)\n",
    "    D = nn.DataParallel(D, device_ids=DEVICE_IDS)\n",
    "    \n",
    "print('T params:', np.sum([np.prod(p.shape) for p in T.parameters()]))\n",
    "print('D params:', np.sum([np.prod(p.shape) for p in D.parameters()]))\n",
    "\n",
    "T_opt = torch.optim.Adam(T.parameters(), lr=T_LR, weight_decay=1e-10)\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=D_LR, weight_decay=1e-10)\n",
    "T_scheduler = torch.optim.lr_scheduler.MultiStepLR(T_opt, milestones=[15000, 25000, 40000, 55000, 70000], gamma=0.5)\n",
    "D_scheduler = torch.optim.lr_scheduler.MultiStepLR(D_opt, milestones=[15000, 25000, 40000, 55000, 70000], gamma=0.5)\n",
    "\n",
    "if CONTINUE > -1:\n",
    "    T_opt.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'T_opt_{SEED}_{CONTINUE}.pt')))\n",
    "    T_scheduler.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'T_scheduler_{SEED}_{CONTINUE}.pt')))\n",
    "    T.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'T_{SEED}_{CONTINUE}.pt')))\n",
    "    D_opt.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'D_opt_{SEED}_{CONTINUE}.pt')))\n",
    "    D.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'D_{SEED}_{CONTINUE}.pt')))\n",
    "    D_scheduler.load_state_dict(torch.load(os.path.join(OUTPUT_PATH, f'D_scheduler_{SEED}_{CONTINUE}.pt')))\n",
    "    \n",
    "torch.manual_seed(0xBADBEEF); np.random.seed(0xBADBEEF)\n",
    "X_fixed, Y_fixed = X_sampler.sample(10), Y_sampler.sample(10)\n",
    "X_fixed = X_fixed[:,None].repeat(1,4,1,1,1)\n",
    "with torch.no_grad():\n",
    "    Z_fixed = torch.randn(10, 4, ZC, 1, 1, device='cuda') * Z_STD\n",
    "    XZ_fixed = (X_fixed, Z_fixed)\n",
    "del X_fixed\n",
    "\n",
    "X_test_fixed, Y_test_fixed = X_test_sampler.sample(10), Y_test_sampler.sample(10)\n",
    "X_test_fixed = X_test_fixed[:,None].repeat(1,4,1,1,1)\n",
    "with torch.no_grad():\n",
    "    Z_test_fixed = torch.randn(10, 4, ZC, 1, 1, device='cuda') * Z_STD\n",
    "    XZ_test_fixed = (X_test_fixed, Z_test_fixed,)\n",
    "del X_test_fixed\n",
    "\n",
    "fig, axes = plot_Z_images(XZ_fixed, Y_fixed, T)\n",
    "fig, axes = plot_random_Z_images(X_sampler, ZC, Z_STD, Y_sampler, T)\n",
    "fig, axes = plot_Z_images(XZ_test_fixed, Y_test_fixed, T)\n",
    "fig, axes = plot_random_Z_images(X_test_sampler, ZC, Z_STD, Y_test_sampler, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33469e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "best_fid = np.inf\n",
    "best_step = 0\n",
    "\n",
    "for step in tqdm(range(CONTINUE+1, MAX_STEPS)):\n",
    "    gamma = min(GAMMA1, GAMMA0 + (GAMMA1-GAMMA0) * step / GAMMA_ITERS)\n",
    "    # T optimization\n",
    "    unfreeze(T); freeze(D)\n",
    "    for t_iter in range(T_ITERS): \n",
    "        T_opt.zero_grad()\n",
    "        X = X_sampler.sample(BATCH_SIZE)[:,None].repeat(1,Z_SIZE,1,1,1)\n",
    "        with torch.no_grad():\n",
    "            Z = torch.randn(BATCH_SIZE, Z_SIZE, ZC, 1, 1, device='cuda') * Z_STD\n",
    "        T_XZ = T(\n",
    "            X.flatten(start_dim=0, end_dim=1), Z.flatten(start_dim=0, end_dim=1)\n",
    "        ).permute(1,2,3,0).reshape(3, IMG_SIZE, IMG_SIZE, -1, Z_SIZE).permute(3,4,0,1,2)\n",
    "        \n",
    "        if COST == 'weak_mse':\n",
    "            # Weak quadratic cost (normalized by DIM)\n",
    "            T_var = T_XZ.var(dim=1).mean()\n",
    "            T_loss = F.mse_loss(X[:,0], T_XZ.mean(dim=1)).mean() - \\\n",
    "            D(T_XZ.flatten(start_dim=0, end_dim=1)).mean() +  T_var * (1 - gamma - 1. / Z_SIZE)\n",
    "        elif COST == 'energy':\n",
    "            # Energy-based quadratic cost (for distance-induced kernel)\n",
    "            T_var = .5 * torch.cdist(T_XZ.flatten(start_dim=2), T_XZ.flatten(start_dim=2)).mean() * Z_SIZE / (Z_SIZE -1)\n",
    "            T_loss = (X-T_XZ).flatten(start_dim=2).norm(dim=2).mean() - \\\n",
    "            D(T_XZ.flatten(start_dim=0, end_dim=1)).mean() - gamma * T_var\n",
    "        elif COST == 'gaussian':\n",
    "            # Gaussian kernel (normalized by DIM)\n",
    "            idx = torch.triu_indices(Z_SIZE, Z_SIZE, offset=1)\n",
    "            T_var = 1 - torch.exp(\n",
    "                -.5*(T_XZ[:,idx[0]]-T_XZ[:,idx[1]]).square().flatten(start_dim=2).mean(dim=2)\n",
    "            ).mean()\n",
    "            T_loss = 1 - torch.exp(-0.5 * (X-T_XZ).square().flatten(start_dim=2).mean(dim=2)).mean() -\\\n",
    "            D(T_XZ.flatten(start_dim=0, end_dim=1)).mean() - gamma * T_var\n",
    "        elif COST == 'laplacian':\n",
    "            # Laplacian kernel (normalized by DIM)\n",
    "            idx = torch.triu_indices(Z_SIZE, Z_SIZE, offset=1)\n",
    "            T_var = 1 - torch.exp(\n",
    "                -(T_XZ[:,idx[0]]-T_XZ[:,idx[1]]).square().flatten(start_dim=2).mean(dim=2).sqrt()\n",
    "            ).mean()\n",
    "            T_loss = 1 - torch.exp(-(X-T_XZ).square().flatten(start_dim=2).mean(dim=2).sqrt()).mean() -\\\n",
    "            D(T_XZ.flatten(start_dim=0, end_dim=1)).mean() - gamma * T_var\n",
    "        else:\n",
    "            raise Exception(\"I do know know this cost!\")\n",
    "        \n",
    "        T_loss.backward(); T_opt.step()\n",
    "    T_scheduler.step()\n",
    "    \n",
    "    writer.add_scalar('var',\n",
    "                      T_var.item(),\n",
    "                      step + 1)\n",
    "    \n",
    "    # wandb.log({'var' : T_var.item()}, step=step)\n",
    "    del T_loss, T_XZ, X, Z, T_var; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    # D optimization\n",
    "    freeze(T); unfreeze(D)\n",
    "    X = X_sampler.sample(BATCH_SIZE)\n",
    "    with torch.no_grad():\n",
    "        Z = torch.randn(BATCH_SIZE, ZC, 1, 1, device='cuda') * Z_STD\n",
    "        T_XZ = T(X,Z)\n",
    "    Y = Y_sampler.sample(BATCH_SIZE)\n",
    "    D_opt.zero_grad()\n",
    "    D_loss = D(T_XZ).mean() - D(Y).mean()\n",
    "    D_loss.backward(); D_opt.step(); D_scheduler.step()\n",
    "    \n",
    "    writer.add_scalar('D_loss',\n",
    "                      D_loss.item(),\n",
    "                      step + 1)\n",
    "    \n",
    "    # wandb.log({f'D_loss' : D_loss.item()}, step=step)\n",
    "    del D_loss, Y, X, T_XZ, Z; gc.collect(); torch.cuda.empty_cache()\n",
    "            \n",
    "    if step % PLOT_INTERVAL == 0:\n",
    "        print('Plotting')\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        fig, axes = plot_Z_images(XZ_fixed, Y_fixed, T)\n",
    "        writer.add_figure('Fixed Images',\n",
    "                          fig,\n",
    "                          global_step=step + 1)\n",
    "        # wandb.log({'Fixed Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_random_Z_images(X_sampler, ZC, Z_STD,  Y_sampler, T)\n",
    "        writer.add_figure('Random Images',\n",
    "                          fig,\n",
    "                          global_step=step + 1)\n",
    "        # wandb.log({'Random Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_Z_images(XZ_test_fixed, Y_test_fixed, T)\n",
    "        writer.add_figure('Fixed Test Images',\n",
    "                          fig,\n",
    "                          global_step=step + 1)\n",
    "        # wandb.log({'Fixed Test Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "        plt.show(fig); plt.close(fig) \n",
    "        \n",
    "        fig, axes = plot_random_Z_images(X_test_sampler, ZC, Z_STD,  Y_test_sampler, T)\n",
    "        writer.add_figure('Random Test Images',\n",
    "                          fig,\n",
    "                          global_step=step + 1)\n",
    "        # wandb.log({'Random Test Images' : [wandb.Image(fig2img(fig))]}, step=step) \n",
    "    \n",
    "    if step % CPKT_INTERVAL == 0:\n",
    "        freeze(T)\n",
    "        torch.save(T.state_dict(), os.path.join(OUTPUT_PATH, f'T_{SEED}_{step}.pt'))\n",
    "        torch.save(D.state_dict(), os.path.join(OUTPUT_PATH, f'D_{SEED}_{step}.pt'))\n",
    "        torch.save(D_opt.state_dict(), os.path.join(OUTPUT_PATH, f'D_opt_{SEED}_{step}.pt'))\n",
    "        torch.save(T_opt.state_dict(), os.path.join(OUTPUT_PATH, f'T_opt_{SEED}_{step}.pt'))\n",
    "        torch.save(D_scheduler.state_dict(), os.path.join(OUTPUT_PATH, f'D_scheduler_{SEED}_{step}.pt'))\n",
    "        torch.save(T_scheduler.state_dict(), os.path.join(OUTPUT_PATH, f'T_scheduler_{SEED}_{step}.pt'))\n",
    "        \n",
    "        print('Computing FID')\n",
    "        mu, sigma = get_Z_pushed_loader_stats(T, X_test_sampler.loader, ZC=ZC, Z_STD=Z_STD, n_epochs=FID_EPOCHS)\n",
    "        fid = calculate_frechet_distance(mu_data, sigma_data, mu, sigma)\n",
    "        writer.add_scalar('FID (Test)',\n",
    "                          fid,\n",
    "                          global_step=step + 1)\n",
    "        # wandb.log({f'FID (Test)' : fid}, step=step)\n",
    "        \n",
    "        print(f\"Current test FID = {fid}, best FID = {best_fid}, step = {step}, best step = {best_step}\")\n",
    "        if fid < best_fid:\n",
    "            best_fid = fid\n",
    "            best_step = step\n",
    "            print(f\"New best FID = {best_fid}, best step = {step}, \")\n",
    "            freeze(T)\n",
    "            torch.save(T.state_dict(), os.path.join(OUTPUT_PATH, f'best_T_{SEED}.pt'))\n",
    "            torch.save(D.state_dict(), os.path.join(OUTPUT_PATH, f'best_D_{SEED}.pt'))\n",
    "            torch.save(D_opt.state_dict(), os.path.join(OUTPUT_PATH, f'best_D_opt_{SEED}.pt'))\n",
    "            torch.save(T_opt.state_dict(), os.path.join(OUTPUT_PATH, f'best_T_opt_{SEED}.pt'))\n",
    "            torch.save(D_scheduler.state_dict(), os.path.join(OUTPUT_PATH, f'best_D_scheduler_{SEED}.pt'))\n",
    "            torch.save(T_scheduler.state_dict(), os.path.join(OUTPUT_PATH, f'best_T_scheduler_{SEED}.pt'))\n",
    "\n",
    "        del mu, sigma\n",
    "    \n",
    "    gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd08d4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "otenv",
   "language": "python",
   "name": "otenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
