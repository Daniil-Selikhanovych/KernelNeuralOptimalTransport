{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import gc\n",
    "\n",
    "from src.tools import freeze, load_dataset, get_Z_pushed_loader_stats\n",
    "from src.fid_score import calculate_frechet_distance\n",
    "from src.cunet import CUNet\n",
    "\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import clear_output\n",
    "from collections import OrderedDict\n",
    "\n",
    "# This needed to use dataloaders for some datasets\n",
    "from PIL import PngImagePlugin\n",
    "LARGE_ENOUGH_NUMBER = 100\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FID scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_ID = 3\n",
    "\n",
    "# DATASET2, DATASET2_PATH = 'handbag', '../../data/handbag_128.hdf5'\n",
    "DATASET1, DATASET1_PATH = 'dtd', '../../data/dtd/images'\n",
    "DATASET2, DATASET2_PATH = 'shoes', '../../data/shoes_128.hdf5'\n",
    "\n",
    "# DATASET1, DATASET1_PATH = 'outdoor', '../../data/outdoor_128.hdf5'\n",
    "# DATASET2, DATASET2_PATH = 'church', '../../data/church_128.hdf5'\n",
    "\n",
    "# DATASET1, DATASET1_PATH = 'celeba_female', '../../data/img_align_celeba'\n",
    "# DATASET2, DATASET2_PATH = 'aligned_anime_faces', '../../data/aligned_anime_faces'\n",
    "\n",
    "IMG_SIZE = 128\n",
    "COST = 'energy'\n",
    "\n",
    "ZC, Z_STD = 128, 1.\n",
    "    \n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f'cuda:{DEVICE_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f'cuda:{DEVICE_ID}')\n",
    "\n",
    "AUGMENTED_DATASETS = ['dtd']\n",
    "FID_EPOCHS = 50 if DATASET1 in AUGMENTED_DATASETS else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'stats/{}_{}_test.json'.format(DATASET2, IMG_SIZE)\n",
    "with open(filename, 'r') as fp:\n",
    "    data_stats = json.load(fp)\n",
    "    mu_data, sigma_data = data_stats['mu'], data_stats['sigma']\n",
    "del data_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_test_sampler = load_dataset(DATASET1, DATASET1_PATH, img_size=IMG_SIZE, batch_size=256)\n",
    "# _, Y_test_sampler = load_dataset(DATASET2, DATASET2_PATH, img_size=IMG_SIZE, batch_size=256)\n",
    "    \n",
    "T = CUNet(3, 3, ZC, base_factor=48)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join('../checkpoints', COST, '{}_{}_{}'.format(DATASET1, DATASET2, IMG_SIZE))\n",
    "model = 'T.pt'\n",
    "path = os.path.join(folder, model)\n",
    "\n",
    "T.load_state_dict(torch.load(path))\n",
    "T.cuda(); freeze(T)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cache/selikhanovych/ot/KernelNeuralOptimalTransport/notebooks/../src/cunet.py:62: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
      "/cache/selikhanovych/ot/KernelNeuralOptimalTransport/notebooks/../src/cunet.py:63: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  diffY // 2, diffY - diffY // 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID = 24.79571868987776\n",
      "FID = 24.959808788050623\n",
      "FID = 24.823207289467234\n",
      "FID = 24.778168681212236\n",
      "FID = 24.854378966612302\n",
      "FID = 24.69220724157134\n",
      "FID = 24.82760368139742\n",
      "FID = 24.768911862425966\n",
      "FID = 24.854055437890963\n",
      "FID = 25.030413809289456\n",
      "--------\n",
      "Mean FID = 24.83844744477953\n",
      "Std FID = 0.09171019746958688\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0xBADBEEF)\n",
    "np.random.seed(0xBADBEEF)\n",
    "\n",
    "num_calculation_fid = 10\n",
    "\n",
    "fid_values = []\n",
    "\n",
    "for _ in range(num_calculation_fid):\n",
    "    mu, sigma = get_Z_pushed_loader_stats(\n",
    "        T, X_test_sampler.loader, ZC=ZC, Z_STD=Z_STD,\n",
    "        n_epochs=FID_EPOCHS, use_downloaded_weights=True\n",
    "    )\n",
    "    fid = calculate_frechet_distance(mu_data, sigma_data, mu, sigma)\n",
    "    print(f\"FID = {fid}\")\n",
    "    fid_values.append(fid)\n",
    "fid_values = np.array(fid_values)\n",
    "fid_mean = np.mean(fid_values)\n",
    "fid_std = np.std(fid_values)\n",
    "print(\"--------\")\n",
    "print(f\"Mean FID = {fid_mean}\")\n",
    "print(f\"Std FID = {fid_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance-similarity trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DEVICE_ID = 0\n",
    "\n",
    "DATASET2, DATASET2_PATH = 'shoes', '../../data/shoes_128.hdf5'\n",
    "DATASET1, DATASET1_PATH = 'dtd', '../../data/dtd/images'\n",
    "\n",
    "IMG_SIZE = 64\n",
    "COST = 'energy'\n",
    "\n",
    "ZC, Z_STD = 128, 1.\n",
    "    \n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f'cuda:{DEVICE_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_test_sampler = load_dataset(DATASET1, DATASET1_PATH, img_size=IMG_SIZE, batch_size=256)\n",
    "_, Y_test_sampler = load_dataset(DATASET2, DATASET2_PATH, img_size=IMG_SIZE, batch_size=256)\n",
    "    \n",
    "T = CondUNetV2(3, 3, ZC, base_factor=48)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.join('../checkpoints', COST, '{}_{}_{}'.format(DATASET1, DATASET2, IMG_SIZE))\n",
    "Z_SIZE = 8\n",
    "X_SIZE = 128\n",
    "X = X_test_sampler.sample(X_SIZE)[:,None].repeat(1,Z_SIZE,1,1,1)\n",
    "Z = torch.randn(X_SIZE, Z_SIZE, ZC, 1, 1, device='cuda') * Z_STD\n",
    "\n",
    "for model in ['T_0.pt', 'T_0.33.pt', 'T_0.66.pt', 'T_1.pt', 'T_1.33.pt']:\n",
    "    path = os.path.join(folder, model)\n",
    "    T.load_state_dict(torch.load(path))\n",
    "    T.cuda(); freeze(T)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        T_XZ = T(\n",
    "            X.flatten(start_dim=0, end_dim=1), Z.flatten(start_dim=0, end_dim=1)\n",
    "        ).permute(1,2,3,0).reshape(3, IMG_SIZE, IMG_SIZE, -1, Z_SIZE).permute(3,4,0,1,2)\n",
    "        var = .5 * torch.cdist(T_XZ.flatten(start_dim=2), T_XZ.flatten(start_dim=2)).mean() * Z_SIZE / (Z_SIZE -1)\n",
    "        dist2 = (X-T_XZ).flatten(start_dim=2).norm(dim=2).mean()\n",
    "        gamma = float(model.split('_')[1][:-3])\n",
    "        cost = (.5 * dist2 - .5 * gamma * var) * 0.5\n",
    "    print(model, gamma)\n",
    "    # Division by 2 since 1/2 in kernel\n",
    "    print('Var:', round(var.item() / 2, 2), 'Dist:', round(dist2.item() / 2, 2))\n",
    "    print('Cost:', round(cost.item(), 2), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
